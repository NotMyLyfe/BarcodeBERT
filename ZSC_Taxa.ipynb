{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ffcc44-0615-4a36-b36b-d12d8d69739b",
   "metadata": {},
   "source": [
    "# ZSC Comparsion of Different Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513070a3-b164-40cd-a5bf-12a4f7ddb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Loading model from /h/pmillana/projects/BIOSCAN_5M_DNA_experiments/model_checkpoints/8_4_4/checkpoint_pretraining.pt\n",
      "\n",
      "Loading model from /h/pmillana/projects/BIOSCAN_5M_DNA_experiments/model_checkpoints/8_4_4/checkpoint_pretraining.pt\n",
      "Loaded model from /h/pmillana/projects/BIOSCAN_5M_DNA_experiments/model_checkpoints/8_4_4/checkpoint_pretraining.pt\n",
      "BarcodeBERT-5M\n",
      "Number of trainable parameters: 129478144\n",
      "Using device: cuda\n",
      "Calculating embeddings for BarcodeBERT\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/BarcodeBERT/unseen.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bfcc37d1434379afa32da9803491d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for BarcodeBERT\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/BarcodeBERT/supervised_test.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e111d4f0a14723af9e35e39f352182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18348, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/pmillana/miniconda3/envs/hyenadna/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/fs01/home/pmillana/projects/BarcodeBERT/baselines/models/dnabert2.py:203: UserWarning: Unable to import Triton; defaulting MosaicBERT attention                 implementation to pytorch (this will reduce throughput when using this model).\n",
      "  self.self = BertUnpadSelfAttention(config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 117068544\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-2\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/DNABERT-2/unseen.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1384889191642ec8028a7cef449df75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-2\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/DNABERT-2/supervised_test.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729f187da7b245d89d2737834bb02089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18348, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/pmillana/miniconda3/envs/hyenadna/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/fs01/home/pmillana/projects/BarcodeBERT/baselines/models/dnabert2.py:203: UserWarning: Unable to import Triton; defaulting MosaicBERT attention                 implementation to pytorch (this will reduce throughput when using this model).\n",
      "  self.self = BertUnpadSelfAttention(config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 117068544\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-S\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/DNABERT-S/unseen.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c21ccb2d04616a93462581a935bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-S\n",
      "/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/DNABERT-S/supervised_test.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca739f096954439b6ba6cc7e9b982f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('.')\n",
    "from baselines.datasets import representations_from_df, labels_from_df \n",
    "from baselines.io import load_baseline_model\n",
    "\n",
    "data_folder = \"BIOSCAN_5M_DNA_experiments/data\"\n",
    " \n",
    "#\"BarcodeBERT_soft_penalty/data\"\n",
    "\n",
    "for model_name in [\"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"NT\", \"Hyena_DNA\"]:\n",
    "    if model_name == \"BarcodeBERT\":\n",
    "        checkpoints = {\"BarcodeBERT-5M\":\"/h/pmillana/projects/BIOSCAN_5M_DNA_experiments/model_checkpoints/8_4_4/checkpoint_pretraining.pt\",\n",
    "                       #\"BarcodeBERT-1.5M\":\"/scratch/ssd004/scratch/pmillana/checkpoints/canada-1.5M/k4-4-4_w1.0_m1.0_r0.0.pt\",\n",
    "                      }\n",
    "        \n",
    "        for ckpt_name in checkpoints:\n",
    "            checkpoint = checkpoints[ckpt_name]\n",
    "            embedder = load_baseline_model(model_name, checkpoint_path=checkpoint, new_vocab=False)\n",
    "\n",
    "            print(ckpt_name)\n",
    "\n",
    "            embedder.name = model_name\n",
    "            \n",
    "            # Ensure model is in eval mode\n",
    "            embedder.model.eval()\n",
    "        \n",
    "            trainable_params = sum(\tp.numel() for p in embedder.model.parameters() if p.requires_grad)\n",
    "        \n",
    "            print(f\"Number of trainable parameters: {trainable_params}\")\n",
    "            \n",
    "            for file in [\"unseen\", \"supervised_test\"]: \n",
    "                filename = f\"/h/pmillana/projects/{data_folder}/{file}.csv\"\n",
    "                embeddings = representations_from_df(filename, embedder, dataset=\"BIOSCAN-5M\", target=\"processid\") #dataset= \"BIOSCAN-5M\"\n",
    "                print(embeddings.shape)\n",
    "\n",
    "            #os.rename(f\"/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/BarcodeBERT\", \n",
    "            #          f\"/scratch/ssd004/scratch/pmillana/embeddings/embeddings/BIOSCAN-5M/{ckpt_name}\")\n",
    "            \n",
    "    else:\n",
    "        embedder = load_baseline_model(model_name)\n",
    "    \n",
    "        embedder.name = model_name\n",
    "        \n",
    "        # Ensure model is in eval mode\n",
    "        embedder.model.eval()\n",
    "    \n",
    "        trainable_params = sum(\tp.numel() for p in embedder.model.parameters() if p.requires_grad)\n",
    "    \n",
    "        print(f\"Number of trainable parameters: {trainable_params}\")\n",
    "        \n",
    "        for file in [\"unseen\", \"supervised_test\"]: \n",
    "            filename = f\"/h/pmillana/projects/{data_folder}/{file}.csv\"\n",
    "            embeddings = representations_from_df(filename, embedder, dataset=\"BIOSCAN-5M\", target=\"processid\") #dataset= \"BIOSCAN-5M\"\n",
    "            print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6718c-53f4-40c8-92b4-df5785a1948b",
   "metadata": {},
   "source": [
    "### This notebook Compares the embedding performance on the 'BIOSCAN-5M' dataset, of seven different DNA barcode-based models: BarcodeBERT-1M, BarcodeBERT-5M, DNABERT, DNABERT-2, DNABERT-S, Hyena_DNA and NT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2971b2-f24a-41f8-8155-ffc35fbe23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import cProfile\n",
    "import pstats\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier, KDTree\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from obj_knn import FinBOL_GBOL\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = \"BIOSCAN-5M\"\n",
    "data_folder = \"BIOSCAN_5M_DNA_experiments/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c832d9-c6b0-4008-a8db-4cc40438127a",
   "metadata": {},
   "source": [
    "### Each sample is labeled at seven taxonomic ranks: class, order, family, subfamily, tribe, genus, and species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db4831-2ade-4dd4-8d68-f47a93c66bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = [\"class\", \"order\", \"family\", \"genus\", \"species\", \"dna_bin\"]\n",
    "#rank_list = [\"dna_bin\"]\n",
    "#rank_list = [\"species\"]\n",
    "encoders = [\"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"Hyena_DNA\", \"NT\"] #, \"DNABERT\"]\n",
    "\n",
    "# Creating the embeddings dictionary to hold all the FinBOL vs GBOL embedding/label data \n",
    "embeddings = {}\n",
    "for encoder in encoders:\n",
    "    embeddings[encoder] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff05da-a071-4014-9454-47615bb4b1f4",
   "metadata": {},
   "source": [
    "### We load embeddings from the test and the unseen_test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be74c3-42d5-4587-9622-af7d6d85bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder in encoders:\n",
    "    # reading the Seen embeddings\n",
    "    embeddings_folder = f\"/scratch/ssd004/scratch/pmillana/embeddings/embeddings/{dataset}\"\n",
    "    with open(f\"{embeddings_folder}/{encoder}/supervised_test.pickle\", \"rb\") as train_handle:\n",
    "        embeddings[encoder][\"Seen\"] = pickle.load(train_handle)\n",
    "\n",
    "    # reading the Unseen embeddings\n",
    "    with open(f\"{embeddings_folder}/{encoder}/unseen.pickle\", \"rb\") as test_handle:\n",
    "        embeddings[encoder][\"Unseen\"] = pickle.load(test_handle)\n",
    "\n",
    "print('Partition lengths:')\n",
    "print(\"Train: \", len(embeddings[encoder][\"Seen\"]['ids']))\n",
    "print(\"Test: \", len(embeddings[encoder][\"Unseen\"]['ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644340ab-9243-49be-903c-7b35ec77643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder in encoders:\n",
    "    print(encoder)\n",
    "    for x in (embeddings[\"BarcodeBERT\"][\"Unseen\"]['ids'][0:3]):\n",
    "        print(x)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034cfca-ecb9-45a8-8688-45b5726e81d7",
   "metadata": {},
   "source": [
    "### Each model encodes a different represenation of the data it was given. To see this, and check that all the data from each model was downloaded properly, a small slice of each encoder's first three embeddings is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fc9a6-974a-4a53-a7cf-56bf17d2f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking embeddings have been loaded correctly for each model\n",
    "for encoder in encoders:\n",
    "    print(encoder)\n",
    "    for x in (embeddings[encoder][\"Seen\"]['data'][0:3]):\n",
    "        print(x[0:5])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06d6f8-c88e-45e1-8627-8046456bf268",
   "metadata": {},
   "source": [
    "### After reading the embedding files from each model, the labels associated with each embeddings must be further processed in order to be used in the ZSC. A single sample from the file contains a 'data' segment (the embedding), and a 'ids' segments which contains a label that holds several different kinds of information about that specific sample. It is this 'ids' segment that must be seperated into several more specific segments including the label of that sample at each of the seven taxonomic ranks listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f298101-7bb2-41ce-989f-4cfadd8da978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(f\"/h/pmillana/projects/{data_folder}/supervised_test.csv\")\n",
    "test = pd.read_csv(f\"/h/pmillana/projects/{data_folder}/unseen.csv\")\n",
    "\n",
    "df_dict = {'Seen': train, 'Unseen':test}\n",
    "\n",
    "for encoder in encoders:\n",
    "    for part in ('Seen', 'Unseen'):\n",
    "        df = df_dict[part]\n",
    "        for rank in rank_list:\n",
    "            if rank not in ['class', 'dna_bin']:\n",
    "                taxa = rank + '_name'\n",
    "            else:\n",
    "                taxa = rank\n",
    "            processid_to_taxa = dict(zip(df['processid'], df[taxa]))\n",
    "            # extract label at each taxonomic rank\n",
    "            embeddings[encoder][part][rank] = [processid_to_taxa.get(processid, None) for processid in embeddings[encoder][part]['ids']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977504e-99ec-4952-9f17-1127dabadc28",
   "metadata": {},
   "source": [
    "### After processing the initial label, each sample now has 10 distinct labels that can be used to group and identify them. Below is an example of the labels concerning the first sample of the FinBOL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3ba62-fa27-4689-bd2f-6c8370967567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying all the new labels\n",
    "for x in embeddings['NT']['Seen'].keys():\n",
    "    if x != 'data':\n",
    "        print(f\"{x}:{' '*(10-len(x))}\" ,embeddings['Hyena_DNA']['Seen'][x][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c9389-4894-4c7c-a10f-ea50639a5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Seen'][df_dict['Seen'][\"processid\"]==\"CRPEB17386-21\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3bdd5-dd54-4a5b-87ef-83cdab41b570",
   "metadata": {},
   "source": [
    "### A single dictionary called 'embeddings' now holds all the data and labels associated with each sample, for each partition, for each model. This example shows the general tree structure for how the data is accessed for each model where each key holds another dictionary except for those at the lowest level which are lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc79d5-1152-4e16-82be-afcb551d481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.keys())\n",
    "print(embeddings['NT'].keys())\n",
    "print(embeddings['NT']['Unseen'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fddc39-450d-4596-9305-cc4f664967c6",
   "metadata": {},
   "source": [
    "# ZSC Analysis\n",
    "the results following the section as well as the associated output files for each model have been made using k=10 for the KNN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e751d-6615-44a6-b2de-0ad4315c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "def zsc_pipeline(X, y_true):\n",
    "        \n",
    "    # Step 1: Dimensionality reduction with UMAP to 50 dimensions\n",
    "    umap_reducer = umap.UMAP(n_components=50, random_state=42)\n",
    "    X_reduced = umap_reducer.fit_transform(X)\n",
    "    \n",
    "    # Step 2: Cluster the reduced embeddings with Agglomerative Clustering (L2, Ward’s method)\n",
    "    agglomerative_clustering = AgglomerativeClustering(n_clusters=4363, linkage='ward')\n",
    "    cluster_labels = agglomerative_clustering.fit_predict(X_reduced)\n",
    "    \n",
    "    # Step 3: Evaluate clustering performance with Adjusted Mutual Information (AMI) score\n",
    "    ami_score = adjusted_mutual_info_score(y_true, cluster_labels)\n",
    "    \n",
    "    print(\"Adjusted Mutual Information (AMI) score:\", ami_score) \n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73734663-fb80-4c4b-a149-1f948531c626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dictionaries for storing results and knn probability data\n",
    "results = {}\n",
    "label_probs = {}\n",
    "\n",
    "for encoder in encoders:\n",
    "    #results[encoder] = {}\n",
    "\n",
    "    # using tqdm to display progress bar for each model\n",
    "    for i in tqdm(range(len(rank_list)),desc=f\"{encoder}{' '*(15-len(encoder))}\"):\n",
    "        rank=rank_list[i]\n",
    "        results[encoder][rank] = {}\n",
    "\n",
    "        # creating a number mapping for the labels at the current taxonomic rank to use for the analysis\n",
    "        #all_labels = sorted(list(set(embeddings[encoder]['Unseen'][rank]+embeddings[encoder]['Seen'][rank])))\n",
    "        #embeddings[encoder]['Seen']['mapped_y_true'] = np.array([all_labels.index(el) for el in embeddings[encoder]['Seen'][rank]])\n",
    "        #embeddings[encoder]['Unseen']['mapped_y_true'] = np.array([all_labels.index(el) for el in embeddings[encoder]['Unseen'][rank]])\n",
    "        \n",
    "        partition_name = \"test_seen + unseen\"\n",
    "        X_part = np.vstack([embeddings[encoder]['Seen']['data'], embeddings[encoder]['Unseen']['data']])\n",
    "        y_part = np.hstack([embeddings[encoder]['Seen'][rank], embeddings[encoder]['Unseen'][rank]])\n",
    "\n",
    "        print(X_part.shape, y_part.shape)\n",
    "            \n",
    "        # ZSC-accuracy\n",
    "        res_part = {}\n",
    "        res_part[\"count\"] = len(y_part)\n",
    "        # Note that these evaluation metrics have all been converted to percentages\n",
    "        res_part[\"AMI\"] = 100.0 * zsc_pipeline(X_part, y_part)\n",
    "        results[encoder][rank][partition_name] = res_part\n",
    "        print(res_part[\"AMI\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda9c32-c3e4-4504-970b-45ac4245236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7815b-8331-47a5-be58-0b90084bdfad",
   "metadata": {},
   "source": [
    "# Results\n",
    "### The results of the analysis are shown below in two different formats\n",
    "NOTE: The metric displayed in the graphs below is accuracy. Several other metrics have been calculated such as the balanced accuracy, all of which are stored in the 'results' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e69d2a-c1b3-4fd7-bc15-380e7cc2e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"results_{dataset}_ZSC.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b18bc-c1f9-4ebd-8548-deba1c7241ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import cProfile\n",
    "import pstats\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier, KDTree\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from obj_knn import FinBOL_GBOL\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = \"BIOSCAN-5M\"\n",
    "#data_folder = \"BIOSCAN_5M_DNA_experiments/data\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"results_{dataset}_ZSC.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "rank_list = [\"class\", \"order\", \"family\", \"genus\", \"species\", \"dna_bin\"]\n",
    "encoders = [\"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"Hyena_DNA\", \"NT\"]#, \"DNABERT\"]\n",
    "\n",
    "x = np.arange(len(rank_list))  # the label locations\n",
    "encoders = sorted(encoders,key=lambda x:results[x]['class']['test_seen + unseen']['AMI'],reverse=True)\n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = -1\n",
    "\n",
    "graph = {}\n",
    "for encoder in encoders:\n",
    "    graph[encoder] = [round(results[encoder][rank]['test_seen + unseen']['AMI'], 2) for rank in rank_list]\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "for rank, measurement in graph.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=rank)\n",
    "    multiplier += 1\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j, encoder in enumerate(encoders):\n",
    "        plt.text(i+offset+(j-multiplier)*(width)+0.1, graph[encoder][i], graph[encoder][i], ha='center', rotation=60, fontsize='x-small')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Rank')\n",
    "\n",
    "ax.set_title('BIOSCAN-5M ZSC encoder comparison')\n",
    "ax.set_xticks(x + width, rank_list)\n",
    "ax.legend(loc='upper right', ncols=2)\n",
    "ax.set_ylim(0, 110)\n",
    "plt.grid(axis=\"y\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa782ca-45e3-4193-a3f8-e409a4103c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[\"#C154A0\", \"#6495ED\", \"#FFBF00\", \"#922B21\", \"#1E8449\", \"#40E0D0\", \"#C18420\"])\n",
    "\n",
    "\n",
    "encoders = [\"DNABERT-2\", \"DNABERT-S\", \"NT\", \"Hyena_DNA\",  \"BarcodeBERT\"] #, \"BarcodeBERT-5M\"]\n",
    "\n",
    "for encoder in encoders:\n",
    "    plt.plot(rank_list, graph[encoder],\"D-\", label = encoder)\n",
    "#plt.title('1NN-probing at different taxonomic levels')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"BIOSCAN_5M_KNN_by_rank_cosine.eps\", dpi=150)\n",
    "plt.savefig(\"BIOSCAN_5M_KNN_by_rank_cosine.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af94a3a-e758-42cb-a033-6433afe097f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
